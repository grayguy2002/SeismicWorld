{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsr0szI6M1mqxIQrZ5Gzey"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Vq0QTenz5lTG"},"outputs":[],"source":["# Mount Google Drive (optional, if you need to save/load data)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# # Clone repository\n","# !git clone https://github.com/yang-song/score_sde_pytorch.git\n","\n","# # Change directory\n","# %cd score_sde_pytorch\n","\n","# # Install dependencies\n","# !pip install -r requirements.txt\n","# !pip install ninja\n","# !pip install ml_collections\n","\n","# # Add to Python path\n","# import sys\n","# sys.path.append('/content/score_sde_pytorch')\n","\n","# Define file path\n","f_path = '/content/drive/MyDrive/DiTing2.0/'\n"]},{"cell_type":"code","source":["#@title backup utilities\n","# not used\n","class MultiScaleAttention(nn.Module):\n","    def __init__(self, d_model, nhead, base_window):\n","        super().__init__()\n","        self.window = base_window # Base window size (e.g., 4)\n","        self.attns = nn.ModuleList([\n","            nn.MultiheadAttention(d_model, nhead, batch_first=True)\n","            for _ in range(3)   # Three different window scales\n","        ])\n","        self.aggregate = nn.Linear(3*d_model, d_model) # Feature fusion\n","\n","    def forward(self, x, pos, scale):\n","        '''\n","        Input: [B, 256, 512]  # (S=256 =16x16 grid)\n","        → Reshape: [B, 16, 16, 512] → [B, 512, 16, 16]\n","        → Unfold (window=4): [B, 512*(4²), 49] → [B, 49, 16, 512]\n","        → Attention → [B, 49, 512]\n","        → Mean → [B, 49, 512]\n","        → Repeat for 3 scales → Concatenate → [B, 49, 3*512]\n","        → Linear → [B, 49, 512]\n","        '''\n","        B, S, D = x.shape # [Batch, Sequence, Features]\n","        windows = []\n","\n","        # Multi-scale windowing\n","        for i in range(3):# i is 'scale factor'\n","            # 1. Calculate dynamic window size\n","            w_size = self.window * (2**i) * scale # Scale adjusts to input size\n","\n","            # 2. Unfold input into windows\n","            unfolded = F.unfold(\n","                        x.view(B, int(sqrt(S)), int(sqrt(S)), D) # Reshape to 4D\n","                        .permute(0, 3, 1, 2),  # [B, D, H, W],\n","                        kernel_size=w_size,\n","                        stride=w_size//2\n","                        ) # Output: [B, D*w_size², num_windows]\n","            # 3. process windows\n","            unfolded = unfolded.view(B, D, w_size**2, -1).permute(0, 3, 2, 1) # [B, num_windows, w_size**2, D]\n","            attn_out, _ = self.attns[i](unfolded, unfolded, unfolded)\n","            windows.append(attn_out.mean(dim=2)) # [B, num_windows, 1, D]\n","\n","        return self.aggregate(torch.cat(windows, dim=-1))\n"],"metadata":{"cellView":"form","id":"LazJ97GpAqxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title dataset structure\n","\n","class PhysicsDataset(Dataset):\n","    def __init__(self, data, patch_size=(16,16,8,4)):\n","        self.data = data  # [B, X, Y, Z, T]\n","        self.patch_size = patch_size\n","\n","    def __getitem__(self, idx):\n","        # Hierarchical patching for computational efficiency\n","        patches = self._create_4d_patches(self.data[idx])\n","        return patches\n","\n","    def _create_4d_patches(self, data):\n","        # Efficient 4D patching with overlap\n","        px, py, pz, pt = self.patch_size\n","        patches = F.unfold(data, kernel_size=(px,py,pz,pt),\n","                          stride=(px//2,py//2,pz//2,pt//2))\n","        return patches\n","\n","class JointDataset(Dataset):\n","    def __init__(self, datasets, patch_size=(16,16,8,4)):\n","        \"\"\"\n","        Initialize JointDataset with multiple PhysicsDataset instances\n","\n","        Args:\n","            datasets (list): List of PhysicsDataset instances\n","            patch_size (tuple): Patch dimensions (px,py,pz,pt)\n","        \"\"\"\n","        if len(datasets) != 4:\n","            raise ValueError(f\"Expected 4 physical datasets, got {len(datasets)}\")\n","\n","        # Verify all datasets have same dimensions\n","        first_data_shape = datasets[0].data.shape\n","        for i, dataset in enumerate(datasets[1:], 1): # the enumeration starts from 1\n","            if dataset.data.shape != first_data_shape:\n","                raise ValueError(f\"Dataset {i} shape {dataset.data.shape} \"\n","                              f\"doesn't match first dataset shape {first_data_shape}\")\n","\n","            if dataset.patch_size != patch_size:\n","                raise ValueError(f\"Dataset {i} patch size {dataset.patch_size} \"\n","                              f\"doesn't match required patch size {patch_size}\")\n","\n","        self.datasets = datasets\n","        self.patch_size = patch_size\n","\n","    def __len__(self):\n","        return len(self.datasets[0])\n","\n","    def __getitem__(self, idx):\n","        # Get patches from each dataset and stack along last dimension\n","        patches_list = []\n","        for dataset in self.datasets:\n","            # Shape: [B, num_patches, px*py*pz*pt]\n","            patches = dataset[idx]\n","            # Add new dimension: [B, num_patches, px*py*pz*pt, 1]\n","            patches = patches.unsqueeze(-1)\n","            patches_list.append(patches)\n","\n","        # Stack along last dimension to get [B, num_patches, px*py*pz*pt, 4]\n","        combined_patches = torch.cat(patches_list, dim=-1)\n","        return combined_patches\n"],"metadata":{"id":"r87c3ICIttmD","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title utilities\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoderLayer\n","from math import sqrt\n","\n","class OptimizedSeismicTransformer(nn.Module):\n","    def __init__(self,\n","                 input_dim=5,\n","                 d_model=512,\n","                 nhead=8,\n","                 num_layers=6,\n","                 output_dim=2,\n","                 local_window=7,\n","                 enable_gradient_checkpointing=False,\n","                 enable_spectral_norm=False,\n","                 enable_uncertainty=True,\n","                 **kwargs):\n","        super().__init__()\n","\n","        # Core model configuration\n","        self.input_dim = input_dim\n","        self.d_model = d_model\n","        self.nhead = nhead\n","        self.num_layers = num_layers\n","        self.output_dim = output_dim\n","        self.local_window = local_window\n","\n","        # Advanced options\n","        self.enable_gradient_checkpointing = enable_gradient_checkpointing\n","        self.enable_spectral_norm = enable_spectral_norm\n","        self.enable_uncertainty = enable_uncertainty\n","\n","        # Initialize components\n","        self._init_components()\n","\n","    def _init_components(self):\n","        \"\"\"Initialize all model components with customizable implementations\"\"\"\n","        self.input_norm = self._create_input_normalization()\n","        self.token_embed = self._create_token_embedding()\n","        self.pos_encoder = self._create_positional_encoder()\n","        self.transformer_blocks = self._create_transformer_blocks()\n","        self.output_heads = self._create_output_heads()\n","\n","    def _create_input_normalization(self):\n","        \"\"\"Customizable input normalization\"\"\"\n","        return nn.LayerNorm(self.input_dim)\n","\n","    def _create_token_embedding(self):\n","        \"\"\"Customizable token embedding\"\"\"\n","        return nn.Sequential(\n","            PhysicsAwareConv3d(self.input_dim, self.d_model),\n","            nn.LayerNorm(self.d_model),\n","            nn.GELU(),\n","            nn.Linear(self.d_model, self.d_model*2),\n","            nn.GELU(),\n","            nn.Linear(self.d_model*2, self.d_model)\n","        )\n","\n","    def _create_positional_encoder(self):\n","        \"\"\"Customizable positional encoding\"\"\"\n","        return HashGridPositionalEncoding4D(self.d_model)\n","\n","    def _create_transformer_blocks(self):\n","        \"\"\"Customizable transformer blocks\"\"\"\n","        blocks = nn.ModuleList([\n","            HierarchicalTransformerBlock(\n","                d_model=self.d_model,\n","                nhead=self.nhead,\n","                local_window=self.local_window*(2**i),\n","                dim_feedforward=4*self.d_model,\n","                dropout=0.1\n","            ) for i in range(self.num_layers)\n","        ])\n","\n","        if self.enable_gradient_checkpointing:\n","            for block in blocks:\n","                block.use_checkpoint = True\n","\n","        return blocks\n","\n","    @abstract\n","    def _create_output_heads(self):\n","        \"\"\"Customizable output heads\"\"\"\n","        return nn.ModuleDict({\n","            'main': PhysicsInformedOutput(\n","                self.d_model,\n","                self.output_dim,\n","                uncertainty=self.enable_uncertainty\n","            )\n","        })\n","\n","    def _validate_input(self, x, pos):\n","        \"\"\"Input validation and shape checking\"\"\"\n","        assert len(x.shape) == 6, f\"Expected 6D input (B,T,X,Y,Z,F), got {x.shape}\"\n","        assert len(pos.shape) == 6, f\"Expected 6D positions (B,T,X,Y,Z,4), got {pos.shape}\"\n","        assert pos.shape[-1] == 4, f\"Position should have 4 coordinates, got {pos.shape[-1]}\"\n","\n","    def register_attention_hooks(self):\n","        \"\"\"Register hooks for attention visualization\"\"\"\n","        self.attention_maps = []\n","        def hook_fn(module, input, output):\n","            self.attention_maps.append(output.detach())\n","\n","        for block in self.transformer_blocks:\n","            block.self_attn.register_forward_hook(hook_fn) # visulizing the output from the pe coor?\n","\n","    def forward(self, x, pos):\n","        \"\"\"Forward pass with modular components\"\"\"\n","        self._validate_input(x, pos)\n","\n","        # Get dimensions\n","        B, T, X, Y, Z, _ = x.shape\n","\n","        # Reshape and normalize input\n","        x = x.view(B, -1, self.input_dim) # be careful with '-1'\n","        x = self.input_norm(x)\n","\n","        # Token embedding\n","        x = self.token_embed(x)\n","\n","        # Position encoding\n","        pos_flat = pos.view(B, -1, 4)\n","        x = self.pos_encoder(x, pos_flat) #HashGridPositionalEncoding4D.forward\n","\n","        # Transformer processing\n","        attn_weights = []\n","        for i, block in enumerate(self.transformer_blocks):\n","            if self.enable_gradient_checkpointing and self.training:\n","                x = torch.utils.checkpoint.checkpoint(\n","                    block, x, pos_flat, 2**i\n","                ) # need massive storage?\n","            else:\n","                x = block(x, pos_flat, local_scale=2**i)\n","\n","        # Output processing\n","        outputs = {}\n","        for head_name, head in self.output_heads.items():\n","            if self.enable_uncertainty:\n","                mean, var = head(x)\n","                outputs[head_name] = {\n","                    'mean': mean.view(B, T, X, Y, Z, -1),\n","                    'variance': var.view(B, T, X, Y, Z, -1)\n","                }\n","            else:\n","                out = head(x)\n","                outputs[head_name] = out.view(B, T, X, Y, Z, -1)\n","\n","        return outputs if len(outputs) > 1 else outputs['main'] # mean&variance > 1\n","\n","    @property\n","    def device(self):\n","        \"\"\"Helper to get model's device\"\"\"\n","        return next(self.parameters()).device\n","\n","class PhysicsAwareConv3d(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.depth_conv = nn.Sequential(\n","            # Depth-wise\n","            nn.Conv3d(in_channels, in_channels,\n","                     kernel_size=(1,3,5), padding='same', groups=in_channels),\n","            nn.BatchNorm3d(in_channels),\n","            nn.GELU(),\n","            # Point-wise\n","            nn.Conv3d(in_channels, out_channels, kernel_size=1),\n","            nn.BatchNorm3d(out_channels)\n","        )\n","\n","        # Initialize weights for better gradient flow\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, m):\n","        if isinstance(m, nn.Conv3d):\n","            nn.init.kaiming_normal_(m.weight)\n","            if m.bias is not None:\n","                nn.init.zeros_(m.bias) # zero bias\n","\n","    def forward(self, x):\n","        # More efficient memory layout\n","        x = x.contiguous()\n","        return self.depth_conv(x.permute(0,5,1,2,3,4)).permute(0,2,3,4,5,1)\n","\n","# memory efficient way to pe 4D data. or 5D?\n","class HashGridPositionalEncoding4D(nn.Module):\n","    def __init__(self, d_model, num_levels=16, level_dim=2, base_resolution=16):\n","        '''\n","        d_model: Output embedding dimension\n","        num_levels: Number of resolution levels (default 16)\n","        level_dim: Feature dimension per level (default 2)\n","        base_resolution: Starting resolution (16^4 entries in first hash table)\n","        '''\n","        super().__init__()\n","        self.d_model = d_model\n","        self.num_levels = num_levels\n","        self.level_dim = level_dim\n","\n","        # Hash table for each level\n","        self.hash_tables = nn.ModuleList([\n","            nn.Embedding(base_resolution ** 4, level_dim) # Creates lookup tables, each with base_resolution ** 4 entries (for 4D space), level_dim features per entry\n","            for _ in range(num_levels)\n","        ])\n","\n","        # Learnable frequency scaling\n","        self.freq_bands = nn.Parameter(torch.exp(\n","            torch.linspace(0., log(128), num_levels))) # Creates learnable frequency scaling factors\n","\n","    #spatial hashing function\n","    def hash_fn(self, coords, level):\n","        # Simple but effective spatial hashing\n","        primes = torch.tensor([1, 2654435761, 805459861, 3674653429]) # Large prime numbers for better hash distribution\n","        x = (coords * self.freq_bands[level] * primes) % (2**32)\n","        return torch.bitwise_xor(x[..., 0], # Combines coordinates using XOR operation\n","               torch.bitwise_xor(x[..., 1],\n","               torch.bitwise_xor(x[..., 2], x[..., 3]))) # The result maps 4D coordinates to hash table indices\n","\n","    def forward(self, x, coords):\n","        B, N = coords.shape[:2]\n","\n","        # Normalize coordinates to [0, 1]\n","        coords = coords.clamp(0, 1)\n","\n","        # Multi-level encoding\n","        features = []\n","        for i, table in enumerate(self.hash_tables): # For each resolution level\n","            hashed = self.hash_fn(coords, i) # Hash the coordinates\n","            features.append(table(hashed)) # Look up features in the corresponding hash table\n","\n","        # Combine features\n","        encoding = torch.cat(features, dim=-1) # Combine features from all levels\n","        return x + encoding # Add to input features\n","\n","class HierarchicalTransformerBlock(nn.Module):\n","    def __init__(self, d_model, nhead, local_window,\n","                 dim_feedforward, dropout=0.1, use_checkpoint=False):\n","        super().__init__()\n","\n","        # Configuration\n","        self.d_model = d_model\n","        self.use_checkpoint = use_checkpoint\n","\n","        # Attention modules\n","        self.local_attn = FlashAttention(\n","            d_model, nhead, local_window\n","        )\n","        self.global_attn = nn.MultiheadAttention(\n","            d_model, nhead, dropout=dropout, batch_first=True\n","        )\n","\n","        # Feed-Forward Network with intermediate activation\n","        self.ffn = nn.Sequential(\n","            nn.Linear(d_model, dim_feedforward),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(dim_feedforward, d_model)\n","        )\n","\n","        # Normalization layers\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        # Dynamic gating mechanism\n","        self.gate_net = nn.Sequential(\n","            nn.Linear(d_model, 2),\n","            nn.Softmax(dim=-1)\n","        )\n","\n","    def _local_attention(self, x, pos, local_scale):\n","        if self.use_checkpoint and self.training:\n","            return torch.utils.checkpoint.checkpoint(\n","                self.local_attn, x, pos, local_scale\n","            )\n","        return self.local_attn(x, pos, local_scale)\n","\n","    def _global_attention(self, x):\n","        if self.use_checkpoint and self.training:\n","            return torch.utils.checkpoint.checkpoint(\n","                lambda q, k, v: self.global_attn(q, k, v)[0],\n","                x, x, x\n","            )\n","        return self.global_attn(x, x, x)[0]\n","\n","    def _compute_dynamic_weights(self, x_local, x_global):\n","        # Compute attention weights based on input features\n","        avg_features = (x_local + x_global) / 2\n","        weights = self.gate_net(avg_features.mean(dim=1, keepdim=True))\n","        return weights[..., 0:1], weights[..., 1:2]\n","\n","    def forward(self, x, pos, local_scale=1):\n","        # Input validation\n","        if not torch.is_tensor(x) or not torch.is_tensor(pos):\n","            raise ValueError(\"Inputs must be tensors\")\n","\n","        # Ensure inputs are on the same device\n","        if x.device != pos.device:\n","            pos = pos.to(x.device)\n","\n","        # Local attention branch with residual\n","        x_local = self._local_attention(x, pos, local_scale)\n","        x_local = self.norm1(x + self.dropout(x_local))\n","\n","        # Global attention branch with residual\n","        x_global = self._global_attention(x_local)\n","        x_global = self.norm2(x_local + self.dropout(x_global))\n","\n","        # Dynamic fusion weights\n","        alpha, beta = self._compute_dynamic_weights(x_local, x_global)\n","\n","        # Adaptive fusion with learned weights\n","        x_fused = alpha * x_global + beta * x_local\n","\n","        # FFN with residual\n","        if self.use_checkpoint and self.training:\n","            x_out = torch.utils.checkpoint.checkpoint(self.ffn, x_fused)\n","        else:\n","            x_out = self.ffn(x_fused)\n","\n","        return self.norm3(x_fused + self.dropout(x_out))\n","\n","    @property\n","    def device(self):\n","        return next(self.parameters()).device\n","\n","class FlashAttention(nn.Module):\n","    def __init__(self, d_model, nhead, base_window):\n","        super().__init__()\n","        self.window = base_window\n","        self.d_model = d_model\n","        self.nhead = nhead\n","\n","        # Single attention module with flash attention\n","        self.attention = nn.MultiheadAttention(\n","            d_model, nhead, batch_first=True,\n","            dropout=0.1\n","        )\n","\n","        # Efficient feature fusion\n","        self.fusion = nn.Sequential(\n","            nn.Linear(3*d_model, d_model),\n","            nn.LayerNorm(d_model)\n","        )\n","\n","        # Cache for window indices\n","        self.register_buffer('window_indices', None)\n","\n","    def create_window_indices(self, size, window_size):\n","      '''This function generates indices for creating windows over a 2D grid of size sqrt(size) x sqrt(size).\n","        size: The total number of elements in the grid.\n","        window_size: The size of the sliding window used to extract patches from the grid.\n","      '''\n","        if self.window_indices is None or self.window_indices.shape[1] != size:\n","            # Precompute indices for efficient windowing\n","            idx = torch.arange(size)\n","            self.window_indices = F.unfold( # extract sliding local blocks (windows) from a larger tensor.\n","                idx.view(1, 1, int(sqrt(size)), int(sqrt(size))),\n","                kernel_size=window_size, # a square window of window_size x window_size\n","                stride=window_size//2 # Using window_size//2 means the windows overlap by half their size, creating a sliding effect.\n","            ) # [1, window_size**2, num_windows]\n","\n","    def forward(self, x, pos, scale):\n","        B, S, D = x.shape\n","        outputs = []\n","\n","        for i in range(3): # 3 is hard-coded window scales\n","            w_size = self.window * (2**i) * scale\n","            self.create_window_indices(S, w_size)\n","\n","            # Efficient windowing using cached indices\n","            # [B, num_windows * window_size**2, D]\n","            windows = x.index_select(1, self.window_indices.view(-1)) # 第一参数：selecting along the second dimension (dim=1)；\n","                                          # 第二参数：self.window_indices contains the precomputed indices for windows, which was created by F.unfold.\n","            # [B*num_windows, window_size**2, D]\n","            windows = windows.view(-1, w_size**2, D)\n","\n","            # Flash attention\n","            with torch.cuda.amp.autocast():\n","                attn_out = F.scaled_dot_product_attention(\n","                    windows, windows, windows,\n","                    dropout_p=0.1 if self.training else 0.0\n","                )\n","\n","            outputs.append(attn_out.mean(dim=1)) # [B * num_windows, D]\n","\n","        return self.fusion(torch.cat(outputs, dim=-1)) # [B * num_windows, D]->[B * num_windows, 3*D]->[B * num_windows, D]\n","\n","class PhysicsInformedOutput(nn.Module):\n","    def __init__(self, d_model, output_dim, uncertainty=True):\n","        super().__init__()\n","        self.uncertainty = uncertainty\n","\n","        self.mean_head = nn.Sequential(\n","            nn.Linear(d_model, d_model//2),\n","            PhysicsConstraintLayer(output_dim),\n","            nn.GELU(),\n","            nn.Linear(d_model//2, output_dim)\n","        )\n","\n","        if uncertainty:\n","            self.var_head = nn.Sequential(\n","                nn.Linear(d_model, d_model//2),\n","                nn.GELU(),\n","                nn.Linear(d_model//2, output_dim),\n","                nn.Softplus()\n","            )\n","\n","    def forward(self, x):\n","        mean = self.mean_head(x)\n","        if not self.uncertainty:\n","            return mean, None\n","        return mean, self.var_head(x) + 1e-6  # Prevent NaN\n","\n","#normalization?\n","class PhysicsConstraintLayer(nn.Module):\n","    def __init__(self, output_dim):\n","        super().__init__()\n","        # Initialize with known velocity ranges\n","        self.register_buffer('vp_bounds', torch.tensor([1500, 6000.0]))\n","        self.register_buffer('vs_bounds', torch.tensor([500, 4000.0]))\n","\n","    def forward(self, x):\n","        # Apply physical constraints\n","        vp_min, vp_max = self.vp_bounds\n","        vs_min, vs_max = self.vs_bounds\n","\n","        x[..., 0] = vp_min + (vp_max - vp_min)*torch.sigmoid(x[..., 0])\n","        x[..., 1] = vs_min + (vs_max - vs_min)*torch.sigmoid(x[..., 1])\n","        return x\n","\n","# training strategy\n","def train_moe(model, train_loader, optimizer, epochs):\n","    for epoch in range(epochs):\n","        for batch in train_loader:\n","            physics_data, target = batch\n","\n","            # Forward pass\n","            pred = model(physics_data)\n","\n","            # Multi-task loss\n","            recon_loss = F.mse_loss(pred, target)\n","            physics_consistency_loss = compute_physics_consistency(pred) # compute_physics_consistency to be added\n","            temporal_coherence_loss = compute_temporal_coherence(pred) # compute_temporal_coherence to be added\n","\n","            loss = (recon_loss +\n","                   0.1 * physics_consistency_loss +\n","                   0.1 * temporal_coherence_loss)\n","\n","            # Backward pass with gradient checkpointing\n","            with torch.cuda.amp.autocast():\n","                loss.backward()\n","            optimizer.step()\n","\n"],"metadata":{"id":"JDitSKyEp1ri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MoE defines\n","\n","class BasePhysicsTransformer(OptimizedSeismicTransformer):\n","    \"\"\"Base class for all physics transformers, inheriting from OptimizedSeismicTransformer\"\"\"\n","    def __init__(self,\n","                 physics_type,\n","                 input_dim=5,\n","                 d_model=512,\n","                 nhead=8,\n","                 num_layers=6,\n","                 output_dim=2,\n","                 local_window=7,\n","                 enable_gradient_checkpointing=False,\n","                 enable_spectral_norm=False,\n","                 enable_uncertainty=True,\n","                 **kwargs):\n","        self.physics_type = physics_type\n","        super().__init__(\n","            input_dim=input_dim,\n","            d_model=d_model,\n","            nhead=nhead,\n","            num_layers=num_layers,\n","            output_dim=output_dim,\n","            local_window=local_window,\n","            enable_gradient_checkpointing=enable_gradient_checkpointing,\n","            enable_spectral_norm=enable_spectral_norm,\n","            enable_uncertainty=enable_uncertainty,\n","            **kwargs\n","        )\n","\n","class SeismicExpert(BasePhysicsTransformer):\n","    def __init__(self, **kwargs):\n","        super().__init__(\n","            physics_type=\"seismic\",\n","            local_window=8,  # Smaller window for high-res features\n","            **kwargs\n","        )\n","\n","    def _create_token_embedding(self):\n","        \"\"\"Specialized seismic embedding with wave propagation awareness\"\"\"\n","        return nn.Sequential(\n","            PhysicsAwareConv3d(self.input_dim, self.d_model),\n","            nn.LayerNorm(self.d_model),\n","            nn.GELU(),\n","            # Additional seismic-specific layers\n","            nn.Conv3d(self.d_model, self.d_model,\n","                     kernel_size=(3,3,3), padding='same', groups=self.d_model),\n","            nn.BatchNorm3d(self.d_model),\n","            nn.GELU(),\n","            nn.Linear(self.d_model, self.d_model)\n","        )\n","\n","    def _create_output_heads(self):\n","        \"\"\"Seismic-specific output with velocity constraints\"\"\"\n","        return nn.ModuleDict({\n","            'main': PhysicsInformedOutput(\n","                self.d_model,\n","                self.output_dim,\n","                uncertainty=self.enable_uncertainty,\n","                bounds={'vp': (1500, 6000), 'vs': (500, 4000)}\n","            )\n","        })\n","\n","class GravityExpert(BasePhysicsTransformer):\n","    def __init__(self, **kwargs):\n","        super().__init__(\n","            physics_type=\"gravity\",\n","            local_window=32,  # Larger window for smooth fields\n","            **kwargs\n","        )\n","\n","    def _create_token_embedding(self):\n","        \"\"\"Gravity-specific embedding with potential field awareness\"\"\"\n","        return nn.Sequential(\n","            nn.Linear(self.input_dim, self.d_model),\n","            nn.LayerNorm(self.d_model),\n","            self._create_gravity_processor(),\n","            nn.Linear(self.d_model*2, self.d_model)\n","        )\n","\n","    def _create_gravity_processor(self):\n","        \"\"\"Gravity-specific processing module\"\"\"\n","        return nn.Sequential(\n","            nn.Conv3d(self.d_model, self.d_model,\n","                     kernel_size=(5,5,5), padding='same', groups=self.d_model), # conv net to extract feature.\n","            nn.BatchNorm3d(self.d_model),\n","            nn.GELU()\n","        )\n","\n","    def _create_output_heads(self):\n","        \"\"\"Gravity-specific output with density constraints\"\"\"\n","        return nn.ModuleDict({\n","            'main': PhysicsInformedOutput(\n","                self.d_model,\n","                self.output_dim,\n","                uncertainty=self.enable_uncertainty,\n","                bounds={'density': (1.0, 5.0)}\n","            )\n","        })\n","\n","class MagneticExpert(BasePhysicsTransformer):\n","    def __init__(self, **kwargs):\n","        super().__init__(\n","            physics_type=\"magnetic\",\n","            local_window=24,  # Medium window for magnetic features\n","            **kwargs\n","        )\n","\n","    def _create_token_embedding(self):\n","        \"\"\"Magnetic-specific embedding with spectral awareness\"\"\"\n","        return nn.Sequential(\n","            nn.Linear(self.input_dim, self.d_model),\n","            self._create_spectral_processor(),\n","            nn.LayerNorm(self.d_model)\n","        )\n","\n","    def _create_spectral_processor(self):\n","        \"\"\"Magnetic-specific spectral processing\"\"\"\n","        return nn.Sequential(\n","            SpectralFeatureExtractor(self.d_model), # SpectralFeatureExtractor to be added\n","            nn.Linear(self.d_model*2, self.d_model)\n","        )\n","\n","    def _create_output_heads(self):\n","        \"\"\"Magnetic-specific output with susceptibility constraints\"\"\"\n","        return nn.ModuleDict({\n","            'main': PhysicsInformedOutput(\n","                self.d_model,\n","                self.output_dim,\n","                uncertainty=self.enable_uncertainty,\n","                bounds={'susceptibility': (0.0, 0.1)}\n","            )\n","        })\n","\n","class ElectricalExpert(BasePhysicsTransformer):\n","    def __init__(self, **kwargs):\n","        super().__init__(\n","            physics_type=\"electrical\",\n","            local_window=16,\n","            dropout=0.2,  # Higher dropout for EM noise\n","            **kwargs\n","        )\n","\n","    def _create_token_embedding(self):\n","        \"\"\"Electrical-specific embedding with resistivity awareness\"\"\"\n","        return nn.Sequential(\n","            nn.Linear(self.input_dim, self.d_model),\n","            self._create_resistivity_processor(),\n","            nn.LayerNorm(self.d_model),\n","            nn.Dropout(0.2)\n","        )\n","\n","    def _create_resistivity_processor(self):\n","        \"\"\"Electrical-specific processing\"\"\"\n","        return nn.Sequential(\n","            ResistivityFeatureExtractor(self.d_model), # ResistivityFeatureExtractor\n","            nn.Linear(self.d_model*2, self.d_model)\n","        )\n","\n","    def _create_output_heads(self):\n","        \"\"\"Electrical-specific output with resistivity constraints\"\"\"\n","        return nn.ModuleDict({\n","            'main': PhysicsInformedOutput(\n","                self.d_model,\n","                self.output_dim,\n","                uncertainty=self.enable_uncertainty,\n","                bounds={'resistivity': (1e-6, 1e6)}\n","            )\n","        })\n"],"metadata":{"id":"L_W9AI49FSrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Phase 2: Fusion expert warm-up with synthetic coupled data.\n","class MultiPhysicsFusion(nn.Module):\n","    def __init__(self, expert_models, hidden_dim=512):\n","        \"\"\"\n","        Initialize fusion model with pre-trained experts\n","\n","        Args:\n","            expert_models (dict): Dictionary of pre-trained expert models\n","                                {'seismic': model1, 'gravity': model2, ...}\n","            hidden_dim (int): Hidden dimension for fusion components\n","        \"\"\"\n","        super().__init__()\n","        self.expert_names = ['seismic', 'gravity', 'magnetic', 'electrical']\n","\n","        # Load pre-trained experts\n","        self.experts = nn.ModuleDict({\n","            name: expert_models[name] # '[name]' is this workable?\n","            for name in self.expert_names\n","        })\n","\n","        # Freeze expert weights\n","        for expert in self.experts.values():\n","            for param in expert.parameters():\n","                param.requires_grad = False\n","\n","        # Initialize fusion components\n","        self.router = nn.Sequential(\n","            nn.Linear(hidden_dim, len(self.expert_names)), #map dim:(h_dim,4)\n","            nn.Softmax(dim=-1)\n","        )\n","\n","        self.cross_physics_attn = nn.MultiheadAttention(\n","            hidden_dim, 8, batch_first=True\n","        )\n","\n","        self.predictor = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Linear(hidden_dim, hidden_dim)\n","        )\n","\n","        # Initialize fusion component weights\n","        self._init_fusion_weights()\n","\n","    def _init_fusion_weights(self):\n","        \"\"\"Initialize weights for fusion components\"\"\"\n","        for m in self.router.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                nn.init.zeros_(m.bias)\n","\n","        for m in self.predictor.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                nn.init.zeros_(m.bias)\n","\n","    def forward(self, physics_inputs):\n","        \"\"\"\n","        Forward pass through fusion model\n","\n","        Args:\n","            physics_inputs (dict): Dictionary of physics inputs\n","                                 {'seismic': tensor1, 'gravity': tensor2, ...}\n","        \"\"\"\n","        expert_outputs = []\n","        routing_weights = []\n","\n","        # Process each physics modality\n","        for name in self.expert_names:\n","            with torch.no_grad():  # No gradients through experts\n","                out = self.experts[name](physics_inputs[name])\n","            expert_outputs.append(out)\n","\n","            # Calculate routing weights (out shape: [batch_size, seq_len, hidden_dim])\n","            # mean over seq_len dimension to get [batch_size, hidden_dim]\n","            weights = self.router(out.mean(dim=1))\n","            routing_weights.append(weights) # [batch_size, hidden_dim]\n","\n","        # Dynamic fusion\n","        routing_matrix = torch.stack(routing_weights, dim=1)  # [batch_size, num_experts, num_experts]\n","        fused_output = sum([out * w.unsqueeze(1).unsqueeze(-1)\n","                          for out, w in zip(expert_outputs, routing_weights)])\n","\n","        # Cross-physics attention\n","        fused_output = self.cross_physics_attn(\n","            fused_output, fused_output, fused_output\n","        )[0]\n","\n","        return self.predictor(fused_output)\n","\n","def train_fusion_warmup(fusion_model, train_loader, val_loader,\n","                       num_epochs=10, learning_rate=1e-4):\n","    \"\"\"\n","    Warm up fusion components using synthetic coupled data\n","\n","    Args:\n","        fusion_model: MultiPhysicsFusion model\n","        train_loader: DataLoader for synthetic coupled training data\n","        val_loader: DataLoader for synthetic coupled validation data\n","        num_epochs: Number of training epochs\n","        learning_rate: Learning rate for fusion components\n","    \"\"\"\n","    # Only optimize fusion components\n","    optimizer = torch.optim.AdamW([\n","        {'params': fusion_model.router.parameters()},\n","        {'params': fusion_model.cross_physics_attn.parameters()},\n","        {'params': fusion_model.predictor.parameters()}\n","    ], lr=learning_rate)\n","\n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n","        optimizer, T_max=num_epochs\n","    )\n","\n","    criterion = nn.MSELoss()\n","\n","    for epoch in range(num_epochs):\n","        fusion_model.train()\n","        train_loss = 0\n","\n","        for batch in train_loader:\n","            optimizer.zero_grad()\n","\n","            # Prepare input data\n","            physics_inputs = {\n","                name: batch[name] for name in fusion_model.expert_names\n","            }\n","            targets = batch['targets']  # Next timestep targets\n","\n","            # Forward pass\n","            outputs = fusion_model(physics_inputs)\n","            loss = criterion(outputs, targets)\n","\n","            # Backward pass (only updates fusion components)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        # Validation\n","        fusion_model.eval()\n","        val_loss = 0\n","\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                physics_inputs = {\n","                    name: batch[name] for name in fusion_model.expert_names\n","                }\n","                targets = batch['targets']\n","\n","                outputs = fusion_model(physics_inputs)\n","                val_loss += criterion(outputs, targets).item()\n","\n","        scheduler.step()\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        print(f\"Train Loss: {train_loss/len(train_loader):.6f}\")\n","        print(f\"Val Loss: {val_loss/len(val_loader):.6f}\")\n","        print(\"-------------------\")\n","\n","# Usage example:\n","def main():\n","    # Load pre-trained expert models\n","    expert_models = {\n","        'seismic': SeismicExpert(...),\n","        'gravity': GravityExpert(...),\n","        'magnetic': MagneticExpert(...),\n","        'electrical': ElectricalExpert(...)\n","    }\n","\n","    # Initialize fusion model with pre-trained experts\n","    fusion_model = MultiPhysicsFusion(expert_models)\n","\n","    # Create synthetic coupled data loaders\n","    train_loader = create_synthetic_dataloader(...)\n","    val_loader = create_synthetic_dataloader(...)\n","\n","    # Warm up fusion components\n","    train_fusion_warmup(fusion_model, train_loader, val_loader)\n"],"metadata":{"cellView":"form","id":"gcowiktqmbNN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Phase 3: Full MoE fine-tuning with field data.\n","\n","def fine_tune_moe(model, train_loader, val_loader,\n","                  num_epochs=20,\n","                  expert_lr=1e-5,    # Lower learning rate for experts\n","                  fusion_lr=1e-4,    # Higher learning rate for fusion\n","                  weight_decay=1e-4,\n","                  gradient_clip=1.0):\n","    \"\"\"\n","    Full model fine-tuning with field data\n","    \"\"\"\n","    # Separate parameter groups for different learning rates\n","    expert_params = []\n","    fusion_params = []\n","\n","    for name, module in model.named_children():\n","        if name == 'experts':\n","            expert_params.extend(module.parameters())\n","        else:\n","            fusion_params.extend(module.parameters())\n","\n","    optimizer = torch.optim.AdamW([\n","        {'params': expert_params, 'lr': expert_lr},\n","        {'params': fusion_params, 'lr': fusion_lr}\n","    ], weight_decay=weight_decay)\n","\n","    # Reduce LR on plateau for both parameter groups\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n","    )\n","\n","    criterion = nn.MSELoss()\n","\n","    # For early stopping\n","    best_val_loss = float('inf')\n","    patience = 5\n","    patience_counter = 0\n","\n","    for epoch in range(num_epochs):\n","        # Training\n","        model.train()\n","        train_loss = 0\n","        expert_original_outputs = {}  # Store original expert predictions\n","\n","        for batch in train_loader:\n","            optimizer.zero_grad()\n","\n","            physics_inputs = {\n","                name: batch[name] for name in model.expert_names\n","            }\n","            targets = batch['targets']\n","\n","            # Store original expert predictions before update\n","            with torch.no_grad():\n","                for name, expert in model.experts.items():\n","                    expert_original_outputs[name] = expert(physics_inputs[name])\n","\n","            # Forward pass\n","            outputs = model(physics_inputs)\n","\n","            # Main prediction loss\n","            pred_loss = criterion(outputs, targets)\n","\n","            # Expert stability regularization\n","            stability_loss = 0\n","            for name, expert in model.experts.items():\n","                current_output = expert(physics_inputs[name])\n","                stability_loss += criterion(current_output,\n","                                         expert_original_outputs[name])\n","\n","            # Combined loss\n","            loss = pred_loss + 0.1 * stability_loss  # Adjust weight as needed\n","\n","            # Backward pass with gradient clipping\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip)\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","\n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                physics_inputs = {\n","                    name: batch[name] for name in model.expert_names\n","                }\n","                targets = batch['targets']\n","                outputs = model(physics_inputs)\n","                val_loss += criterion(outputs, targets).item()\n","\n","        avg_val_loss = val_loss / len(val_loader)\n","        scheduler.step(avg_val_loss)\n","\n","        # Early stopping check\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            patience_counter = 0\n","            # Save best model\n","            torch.save(model.state_dict(), 'best_model.pth')\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(\"Early stopping triggered\")\n","                break\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        print(f\"Train Loss: {train_loss/len(train_loader):.6f}\")\n","        print(f\"Val Loss: {avg_val_loss:.6f}\")\n","        print(\"-------------------\")\n","\n","# Usage example:\n","def main():\n","    # Load model from Phase 2\n","    model = MultiPhysicsFusion.load_from_checkpoint('phase2_model.pth')\n","\n","    # Create field data loaders\n","    train_loader = create_field_dataloader(...)\n","    val_loader = create_field_dataloader(...)\n","\n","    # Fine-tune\n","    fine_tune_moe(model, train_loader, val_loader)"],"metadata":{"id":"o5Ags2Y5r5a7"},"execution_count":null,"outputs":[]}]}